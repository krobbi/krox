// LoxKrox Generator
// A source generator for LoxKrox.
// Copyright (c) 2023 Chris Roberts (Krobbizoid).
// Released under the MIT License:
// https://krobbi.github.io/license/2023/mit.txt

// Generate LoxKrox.
fun generate_loxkrox(is_debug, add_line, add_module){
	add_line("// LoxKrox");
	add_line("// A Krox compiler written in Lox.");
	add_line("// Copyright (c) 2023 Chris Roberts (Krobbizoid).");
	add_line("// Released under the MIT License:");
	add_line("// https://krobbi.github.io/license/2023/mit.txt");
	add_line("");
	add_line("// This file was generated by `generator.lox`. Do not edit it directly.");
	add_line("// Run `generator.lox` or use `make regen` to regenerate LoxKrox from source.");
	add_line("");
	
	if(is_debug){
		add_line("// This is a debug build of LoxKrox.");
		add_line("// !!! Regenerate a release build before publishing.");
	}
	
	// Strings.
	add_module("string/char.lox");
	add_module("string/string.lox");
	
	// Collections.
	add_module("collections/list_node.lox");
	add_module("collections/list_iterator.lox");
	add_module("collections/list.lox");
	add_module("collections/map_node.lox");
	add_module("collections/map.lox");
	
	// Logger.
	add_module("logger/span.lox");
	add_module("logger/log_record.lox");
	add_module("logger/logger.lox");
	
	// Lexer.
	add_module("lexer/token_type.lox");
	add_module("lexer/token.lox");
	add_module("lexer/lexer.lox");
	
	// AST nodes.
	add_module("ast/ast_node.lox");
	add_module("ast/nodes/block_stmt_ast_node.lox");
	add_module("ast/nodes/export_ast_node.lox");
	add_module("ast/nodes/export_item_ast_node.lox");
	add_module("ast/nodes/expr_stmt_ast_node.lox");
	add_module("ast/nodes/fn_stmt_ast_node.lox");
	add_module("ast/nodes/import_ast_node.lox");
	add_module("ast/nodes/import_item_ast_node.lox");
	add_module("ast/nodes/literal_expr_ast_node.lox");
	add_module("ast/nodes/module_ast_node.lox");
	add_module("ast/nodes/nop_stmt_ast_node.lox");
	add_module("ast/nodes/paren_expr_ast_node.lox");
	add_module("ast/nodes/print_stmt_ast_node.lox");
	add_module("ast/nodes/program_ast_node.lox");
	
	// AST utilities.
	add_module("ast/ast_visitor.lox");
	add_module("ast/printer/ast_printer_node.lox");
	add_module("ast/printer/ast_printer.lox");
	
	// Parser.
	add_module("parser/parser.lox");
	
	// Importer.
	add_module("importer/importer.lox");
	
	// Lifecycle.
	add_module("tests/run_tests.lox");
	add_module("core/main.lox");
}

// Define reserved keywords and identifiers.
fun reserve_words(reserve){
	// Keywords.
	reserve("and");
	reserve("class");
	reserve("else");
	reserve("false");
	reserve("for");
	reserve("fun");
	reserve("if");
	reserve("nil");
	reserve("or");
	reserve("print");
	reserve("return");
	reserve("super");
	reserve("this");
	reserve("true");
	reserve("var");
	reserve("while");
	
	// Special identifiers.
	reserve("clock");
	reserve("init");
	
	// Intrinsics.
	reserve("_argc");
	reserve("_argv");
	reserve("_chr");
	reserve("_close");
	reserve("_get");
	reserve("_length");
	reserve("_ord");
	reserve("_put");
	reserve("_read");
	reserve("_stderr");
	reserve("_stdin");
	reserve("_stdout");
	reserve("_substring");
	reserve("_trunc");
	reserve("_write");
}

// Character constants.
var CHAR_TAB = 9; // Tab.
var CHAR_LF = 10; // Line feed.
var CHAR_CR = 13; // Carriage return.
var CHAR_SPACE = _ord(" "); // Space.
var CHAR_BANG = _ord("!"); // Exclamation mark.
var CHAR_QUOTE = 34; // Quotation mark.
var CHAR_DOT = _ord("."); // Dot.
var CHAR_SLASH = _ord("/"); // Slash.
var CHAR_0 = _ord("0"); // Digit 0.
var CHAR_9 = _ord("9"); // Digit 9.
var CHAR_LT = _ord("<"); // Less than.
var CHAR_EQ = _ord("="); // Equals.
var CHAR_GT = _ord(">"); // Greater than.
var CHAR_UPPER_A = _ord("A"); // Uppercase letter A.
var CHAR_UPPER_Z = _ord("Z"); // Uppercase letter Z.
var CHAR_UNDERSCORE = _ord("_"); // Underscore.
var CHAR_LOWER_A = _ord("a"); // Lowercase letter A.
var CHAR_LOWER_Z = _ord("z"); // Lowercase letter Z.

// Put a string of text to an output stream.
fun put_string(string, stream){
	var string_length = _length(string);
	
	for(var i = 0; i < string_length; i = i + 1){
		_put(_ord(_substring(string, i, 1)), stream);
	}
}

// Put a line of text to an output stream.
fun put_line(line, stream){
	put_string(line, stream);
	_put(CHAR_LF, stream);
}

// Print an error message.
fun print_error(message){
	put_line(message, _stderr());
}

// Pad a message to a length with a suffix.
fun pad(message, length, suffix){
	var message_length = _length(message);
	
	while(message_length < length){
		message = message + suffix;
		message_length = message_length + 1;
	}
	
	return message;
}

// Return a path's parent path.
fun get_path_parent(path){
	var path_length = _length(path);
	var parent_path = "";
	var parent_path_length = 0;
	
	for(var i = 0; i < path_length; i = i + 1){
		var char_string = _substring(path, i, 1);
		
		if(char_string == "/" or char_string == "\"){
			parent_path = parent_path + "/";
			parent_path_length = i + 1;
		} else {
			parent_path = parent_path + char_string;
		}
	}
	
	return _substring(parent_path, 0, parent_path_length);
}

// Token types.
var TOKEN_NONE = 0; // Whitespace or comment.
var TOKEN_EOF = 1; // End of file.
var TOKEN_DEFAULT = 2; // Generic token.
var TOKEN_WORD = 3; // Identifier or keyword.
var TOKEN_INTEGER = 4; // Number token without a decimal point.
var TOKEN_REAL = 5; // Number token with a decimal point.
var TOKEN_DOT = 6; // Dot token.
var TOKEN_COMPARISON = 7; // Token that may be expanded with equals.
var TOKEN_EQUAL = 8; // Equals token.
var TOKEN_EQUAL_EQUAL = 9; // Double equals token.

// A Lox token.
class Token {
	// Initialize the token's type and lexeme.
	init(type, lexeme){
		// The token's type.
		this.type = type;
		
		// The token's lexeme.
		this.lexeme = lexeme;
	}
	
	// Return whether the token should be separated from a next token.
	has_separation(next){
		if(this.type == TOKEN_WORD){
			return next.type == TOKEN_WORD or next.type == TOKEN_INTEGER or next.type == TOKEN_REAL;
		} else if(this.type == TOKEN_INTEGER){
			return next.type == TOKEN_INTEGER or next.type == TOKEN_REAL or next.type == TOKEN_DOT;
		} else if(this.type == TOKEN_REAL){
			return next.type == TOKEN_INTEGER or next.type == TOKEN_REAL;
		} else if(this.type == TOKEN_COMPARISON or this.type == TOKEN_EQUAL){
			return next.type == TOKEN_EQUAL or next.type == TOKEN_EQUAL_EQUAL;
		} else {
			return false;
		}
	}
}

// Return a new lexer closure from an input stream.
fun create_lexer(stream){
	var next = _get(stream);
	
	// Return whether a character is a whitespace character.
	fun is_whitespace(char){
		return char == CHAR_TAB or char == CHAR_LF or char == CHAR_CR or char == CHAR_SPACE;
	}
	
	// Return whether a character is a digit character.
	fun is_digit(char){
		return char >= CHAR_0 and char <= CHAR_9;
	}
	
	// Return whether a character is an alphabetical character.
	fun is_alpha(char){
		return (
			char >= CHAR_LOWER_A and char <= CHAR_LOWER_Z
			or char == CHAR_UNDERSCORE
			or char >= CHAR_UPPER_A and char <= CHAR_UPPER_Z
		);
	}
	
	// Advance the next character and return it as a string.
	fun advance(){
		var char_string = _chr(next);
		next = _get(stream);
		return char_string;
	}
	
	// Return the next token or none token from the input stream.
	fun scan_raw_token(){
		if(!next){
			return Token(TOKEN_EOF, "");
		} else if(is_whitespace(next)){
			while(is_whitespace(next)){
				advance();
			}
			
			return Token(TOKEN_NONE, "");
		} else if(next == CHAR_SLASH){
			advance();
			
			if(next == CHAR_SLASH){
				while(next and next != CHAR_LF){
					advance();
				}
				
				return Token(TOKEN_NONE, "");
			} else {
				return Token(TOKEN_DEFAULT, "/");
			}
		} else if(is_alpha(next)){
			var lexeme = advance();
			
			while(is_alpha(next) or is_digit(next)){
				lexeme = lexeme + advance();
			}
			
			return Token(TOKEN_WORD, lexeme);
		} else if(is_digit(next)){
			var lexeme = advance();
			
			while(is_digit(next)){
				lexeme = lexeme + advance();
			}
			
			if(next == CHAR_DOT){
				lexeme = lexeme + advance();
				
				while(is_digit(next)){
					lexeme = lexeme + advance();
				}
				
				return Token(TOKEN_REAL, lexeme);
			} else {
				return Token(TOKEN_INTEGER, lexeme);
			}
		} else if(next == CHAR_DOT){
			return Token(TOKEN_DOT, advance());
		} else if(next == CHAR_BANG or next == CHAR_LT or next == CHAR_EQ or next == CHAR_GT){
			var is_eq = next == CHAR_EQ;
			var type = TOKEN_DEFAULT;
			var lexeme = advance();
			
			if(next == CHAR_EQ){
				if(is_eq){
					type = TOKEN_EQUAL_EQUAL;
				}
				
				return Token(type, lexeme + advance());
			} else {
				if(is_eq){
					type = TOKEN_EQUAL;
				} else {
					type = TOKEN_COMPARISON;
				}
				
				return Token(type, lexeme);
			}
		} else if(next == CHAR_QUOTE){
			var lexeme = advance();
			
			while(next and next != CHAR_QUOTE){
				lexeme = lexeme + advance();
			}
			
			if(next == CHAR_QUOTE){
				lexeme = lexeme + advance();
			}
			
			return Token(TOKEN_DEFAULT, lexeme);
		} else {
			return Token(TOKEN_DEFAULT, advance());
		}
	}
	
	// Return the next token from the input stream.
	fun scan_token(){
		var token = scan_raw_token();
		
		while(token.type == TOKEN_NONE){
			token = scan_raw_token();
		}
		
		return token;
	}
	
	return scan_token;
}

// Return a new minifier closure from an output stream.
fun create_minifier(output_stream){
	var width = 0;
	var manglings = nil;
	var mangle_index = 0;
	
	// Define a mangling from a source word to a target word.
	fun define_mangling(source, target){
		// A mangling from a source word to a target word.
		class Mangling {
			// Initialize the mangling's source, target, and next mangling.
			init(source, target, next){
				// The mangling's source word.
				this.source = source;
				
				// The mangling's target word.
				this.target = target;
				
				// The mangling's next mangling.
				this.next = next;
			}
		}
		
		manglings = Mangling(source, target, manglings);
	}
	
	// Return a new word from an index.
	fun create_word(index){
		var chars = "abcdefghijklmnopqrstuvwxyz_ABCDEFGHIJKLMNOPQRSTUVWXYZ";
		var base = _length(chars);
		var place = base;
		
		while(place <= index){
			place = place * base;
		}
		
		var word = "";
		
		while(place >= base){
			place = place / base;
			var digit = _trunc(index / place);
			index = index - digit * place;
			word = word + _substring(chars, digit, 1);
		}
		
		return word;
	}
	
	// Return whether a mangled word is already defined.
	fun has_mangling(word){
		var mangling = manglings;
		
		while(mangling){
			if(mangling.target == word){
				return true;
			}
			
			mangling = mangling.next;
		}
		
		return false;
	}
	
	// Return a word's mangled equivalent.
	fun mangle(word){
		var mangling = manglings;
		
		while(mangling){
			if(mangling.source == word){
				return mangling.target;
			}
			
			mangling = mangling.next;
		}
		
		var mangled = create_word(mangle_index);
		mangle_index = mangle_index + 1;
		
		while(has_mangling(mangled)){
			mangled = create_word(mangle_index);
			mangle_index = mangle_index + 1;
		}
		
		define_mangling(word, mangled);
		return mangled;
	}
	
	// Reserve a word as unmangled.
	fun reserve(word){
		define_mangling(word, word);
	}
	
	reserve_words(reserve);
	
	// Minify an input stream to the output stream.
	fun minify_input(input_stream){
		var scan_token = create_lexer(input_stream);
		var previous_token = Token(TOKEN_NONE, "");
		var token = scan_token();
		
		while(token.type != TOKEN_EOF){
			if(token.type == TOKEN_WORD){
				token.lexeme = mangle(token.lexeme);
			}
			
			var is_separated = previous_token.has_separation(token);
			var token_length = _length(token.lexeme);
			
			if(is_separated){
				width = width + 1;
			}
			
			if(width + token_length > 100){
				_put(CHAR_LF, output_stream);
				width = 0;
			} else if(is_separated){
				_put(CHAR_SPACE, output_stream);
			}
			
			width = width + token_length;
			put_string(token.lexeme, output_stream);
			previous_token = token;
			token = scan_token();
		}
	}
	
	return minify_input;
}

// Run LoxKrox generator from a base path and debug status.
fun run_generator(base_path, is_debug){
	var write_stream = _write(base_path + "krox.lox");
	
	if(!write_stream){
		print_error("Failed to open `krox.lox` for writing.");
		return;
	}
	
	// Add a line to the write stream.
	fun add_line(line){
		put_line(line, write_stream);
	}
	
	var minify_input = create_minifier(write_stream);
	
	// Add a module to the write stream.
	fun add_module(module){
		if(is_debug){
			add_line("");
			add_line(pad("// MODULE // `" + module + "` // ====", 77, "=") + " //");
			add_line("");
		}
		
		var read_stream = _read(base_path + module);
		
		if(!read_stream){
			print_error("Failed to open `" + module + "` for reading. File may not exist.");
			
			if(!is_debug){
				add_line("");
				add_line("");
			}
			
			add_line("// !!! Failed to read `" + module + "`.");
			
			if(!is_debug){
				add_line("");
			}
			
			return;
		}
		
		if(is_debug){
			var char = _get(read_stream);
			
			while(char){
				_put(char, write_stream);
				char = _get(read_stream);
			}
		} else {
			minify_input(read_stream);
		}
		
		if(!_close(read_stream)){
			print_error("Failed to close `" + module + "` after reading.");
		}
	}
	
	generate_loxkrox(is_debug, add_line, add_module);
	
	if(!is_debug){
		add_line("");
	}
	
	if(!_close(write_stream)){
		print_error("Failed to close `krox.lox` after writing.");
	}
}

// Run LoxKrox generator from arguments.
fun main(){
	var has_valid_arguments = false;
	var is_debug = false;
	
	if(_argc() == 1){
		has_valid_arguments = true;
	} else if(_argc() == 2 and _argv(1) == "--debug"){
		has_valid_arguments = true;
		is_debug = true;
	}
	
	if(has_valid_arguments){
		run_generator(get_path_parent(_argv(0)), is_debug);
	} else {
		print_error("Expected arguments `generator.lox [--debug]`.");
	}
}

main();
